# -*- coding: utf-8 -*-
"""
===================================
Aè‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ - AIåˆ†æå±‚
===================================

èŒè´£ï¼š
1. å°è£… Gemini API è°ƒç”¨é€»è¾‘
2. åˆ©ç”¨ Google Search Grounding è·å–å®æ—¶æ–°é—»
3. ç»“åˆæŠ€æœ¯é¢å’Œæ¶ˆæ¯é¢ç”Ÿæˆåˆ†ææŠ¥å‘Š
"""

import json
import logging
import time
from dataclasses import dataclass
from typing import Optional, Dict, Any, List

from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
    before_sleep_log,
)

from config import get_config

logger = logging.getLogger(__name__)


# è‚¡ç¥¨åç§°æ˜ å°„ï¼ˆå¸¸è§è‚¡ç¥¨ï¼‰
STOCK_NAME_MAP = {
    '600519': 'è´µå·èŒ…å°',
    '000001': 'å¹³å®‰é“¶è¡Œ',
    '300750': 'å®å¾·æ—¶ä»£',
    '002594': 'æ¯”äºšè¿ª',
    '600036': 'æ‹›å•†é“¶è¡Œ',
    '601318': 'ä¸­å›½å¹³å®‰',
    '000858': 'äº”ç²®æ¶²',
    '600276': 'æ’ç‘åŒ»è¯',
    '601012': 'éš†åŸºç»¿èƒ½',
    '002475': 'ç«‹è®¯ç²¾å¯†',
    '300059': 'ä¸œæ–¹è´¢å¯Œ',
    '002415': 'æµ·åº·å¨è§†',
    '600900': 'é•¿æ±Ÿç”µåŠ›',
    '601166': 'å…´ä¸šé“¶è¡Œ',
    '600028': 'ä¸­å›½çŸ³åŒ–',
}


@dataclass
class AnalysisResult:
    """
    AI åˆ†æç»“æœæ•°æ®ç±» - å†³ç­–ä»ªè¡¨ç›˜ç‰ˆ
    
    å°è£… Gemini è¿”å›çš„åˆ†æç»“æœï¼ŒåŒ…å«å†³ç­–ä»ªè¡¨ç›˜å’Œè¯¦ç»†åˆ†æ
    """
    code: str
    name: str
    
    # ========== æ ¸å¿ƒæŒ‡æ ‡ ==========
    sentiment_score: int  # ç»¼åˆè¯„åˆ† 0-100 (>70å¼ºçƒˆçœ‹å¤š, >60çœ‹å¤š, 40-60éœ‡è¡, <40çœ‹ç©º)
    trend_prediction: str  # è¶‹åŠ¿é¢„æµ‹ï¼šå¼ºçƒˆçœ‹å¤š/çœ‹å¤š/éœ‡è¡/çœ‹ç©º/å¼ºçƒˆçœ‹ç©º
    operation_advice: str  # æ“ä½œå»ºè®®ï¼šä¹°å…¥/åŠ ä»“/æŒæœ‰/å‡ä»“/å–å‡º/è§‚æœ›
    confidence_level: str = "ä¸­"  # ç½®ä¿¡åº¦ï¼šé«˜/ä¸­/ä½
    
    # ========== å†³ç­–ä»ªè¡¨ç›˜ (æ–°å¢) ==========
    dashboard: Optional[Dict[str, Any]] = None  # å®Œæ•´çš„å†³ç­–ä»ªè¡¨ç›˜æ•°æ®
    
    # ========== èµ°åŠ¿åˆ†æ ==========
    trend_analysis: str = ""  # èµ°åŠ¿å½¢æ€åˆ†æï¼ˆæ”¯æ’‘ä½ã€å‹åŠ›ä½ã€è¶‹åŠ¿çº¿ç­‰ï¼‰
    short_term_outlook: str = ""  # çŸ­æœŸå±•æœ›ï¼ˆ1-3æ—¥ï¼‰
    medium_term_outlook: str = ""  # ä¸­æœŸå±•æœ›ï¼ˆ1-2å‘¨ï¼‰
    
    # ========== æŠ€æœ¯é¢åˆ†æ ==========
    technical_analysis: str = ""  # æŠ€æœ¯æŒ‡æ ‡ç»¼åˆåˆ†æ
    ma_analysis: str = ""  # å‡çº¿åˆ†æï¼ˆå¤šå¤´/ç©ºå¤´æ’åˆ—ï¼Œé‡‘å‰/æ­»å‰ç­‰ï¼‰
    volume_analysis: str = ""  # é‡èƒ½åˆ†æï¼ˆæ”¾é‡/ç¼©é‡ï¼Œä¸»åŠ›åŠ¨å‘ç­‰ï¼‰
    pattern_analysis: str = ""  # Kçº¿å½¢æ€åˆ†æ
    
    # ========== åŸºæœ¬é¢åˆ†æ ==========
    fundamental_analysis: str = ""  # åŸºæœ¬é¢ç»¼åˆåˆ†æ
    sector_position: str = ""  # æ¿å—åœ°ä½å’Œè¡Œä¸šè¶‹åŠ¿
    company_highlights: str = ""  # å…¬å¸äº®ç‚¹/é£é™©ç‚¹
    
    # ========== æƒ…ç»ªé¢/æ¶ˆæ¯é¢åˆ†æ ==========
    news_summary: str = ""  # è¿‘æœŸé‡è¦æ–°é—»/å…¬å‘Šæ‘˜è¦
    market_sentiment: str = ""  # å¸‚åœºæƒ…ç»ªåˆ†æ
    hot_topics: str = ""  # ç›¸å…³çƒ­ç‚¹è¯é¢˜
    
    # ========== ç»¼åˆåˆ†æ ==========
    analysis_summary: str = ""  # ç»¼åˆåˆ†ææ‘˜è¦
    key_points: str = ""  # æ ¸å¿ƒçœ‹ç‚¹ï¼ˆ3-5ä¸ªè¦ç‚¹ï¼‰
    risk_warning: str = ""  # é£é™©æç¤º
    buy_reason: str = ""  # ä¹°å…¥/å–å‡ºç†ç”±
    
    # ========== å…ƒæ•°æ® ==========
    raw_response: Optional[str] = None  # åŸå§‹å“åº”ï¼ˆè°ƒè¯•ç”¨ï¼‰
    search_performed: bool = False  # æ˜¯å¦æ‰§è¡Œäº†è”ç½‘æœç´¢
    data_sources: str = ""  # æ•°æ®æ¥æºè¯´æ˜
    success: bool = True
    error_message: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'code': self.code,
            'name': self.name,
            'sentiment_score': self.sentiment_score,
            'trend_prediction': self.trend_prediction,
            'operation_advice': self.operation_advice,
            'confidence_level': self.confidence_level,
            'dashboard': self.dashboard,  # å†³ç­–ä»ªè¡¨ç›˜æ•°æ®
            'trend_analysis': self.trend_analysis,
            'short_term_outlook': self.short_term_outlook,
            'medium_term_outlook': self.medium_term_outlook,
            'technical_analysis': self.technical_analysis,
            'ma_analysis': self.ma_analysis,
            'volume_analysis': self.volume_analysis,
            'pattern_analysis': self.pattern_analysis,
            'fundamental_analysis': self.fundamental_analysis,
            'sector_position': self.sector_position,
            'company_highlights': self.company_highlights,
            'news_summary': self.news_summary,
            'market_sentiment': self.market_sentiment,
            'hot_topics': self.hot_topics,
            'analysis_summary': self.analysis_summary,
            'key_points': self.key_points,
            'risk_warning': self.risk_warning,
            'buy_reason': self.buy_reason,
            'search_performed': self.search_performed,
            'success': self.success,
            'error_message': self.error_message,
        }
    
    def get_core_conclusion(self) -> str:
        """è·å–æ ¸å¿ƒç»“è®ºï¼ˆä¸€å¥è¯ï¼‰"""
        if self.dashboard and 'core_conclusion' in self.dashboard:
            return self.dashboard['core_conclusion'].get('one_sentence', self.analysis_summary)
        return self.analysis_summary
    
    def get_position_advice(self, has_position: bool = False) -> str:
        """è·å–æŒä»“å»ºè®®"""
        if self.dashboard and 'core_conclusion' in self.dashboard:
            pos_advice = self.dashboard['core_conclusion'].get('position_advice', {})
            if has_position:
                return pos_advice.get('has_position', self.operation_advice)
            return pos_advice.get('no_position', self.operation_advice)
        return self.operation_advice
    
    def get_sniper_points(self) -> Dict[str, str]:
        """è·å–ç‹™å‡»ç‚¹ä½"""
        if self.dashboard and 'battle_plan' in self.dashboard:
            return self.dashboard['battle_plan'].get('sniper_points', {})
        return {}
    
    def get_checklist(self) -> List[str]:
        """è·å–æ£€æŸ¥æ¸…å•"""
        if self.dashboard and 'battle_plan' in self.dashboard:
            return self.dashboard['battle_plan'].get('action_checklist', [])
        return []
    
    def get_risk_alerts(self) -> List[str]:
        """è·å–é£é™©è­¦æŠ¥"""
        if self.dashboard and 'intelligence' in self.dashboard:
            return self.dashboard['intelligence'].get('risk_alerts', [])
        return []
    
    def get_emoji(self) -> str:
        """æ ¹æ®æ“ä½œå»ºè®®è¿”å›å¯¹åº” emoji"""
        emoji_map = {
            'ä¹°å…¥': 'ğŸŸ¢',
            'åŠ ä»“': 'ğŸŸ¢',
            'å¼ºçƒˆä¹°å…¥': 'ğŸ’š',
            'æŒæœ‰': 'ğŸŸ¡',
            'è§‚æœ›': 'âšª',
            'å‡ä»“': 'ğŸŸ ',
            'å–å‡º': 'ğŸ”´',
            'å¼ºçƒˆå–å‡º': 'âŒ',
        }
        return emoji_map.get(self.operation_advice, 'ğŸŸ¡')
    
    def get_confidence_stars(self) -> str:
        """è¿”å›ç½®ä¿¡åº¦æ˜Ÿçº§"""
        star_map = {'é«˜': 'â­â­â­', 'ä¸­': 'â­â­', 'ä½': 'â­'}
        return star_map.get(self.confidence_level, 'â­â­')


class GeminiAnalyzer:
    """
    Gemini AI åˆ†æå™¨
    
    èŒè´£ï¼š
    1. è°ƒç”¨ Google Gemini API è¿›è¡Œè‚¡ç¥¨åˆ†æ
    2. ç»“åˆé¢„å…ˆæœç´¢çš„æ–°é—»å’ŒæŠ€æœ¯é¢æ•°æ®ç”Ÿæˆåˆ†ææŠ¥å‘Š
    3. è§£æ AI è¿”å›çš„ JSON æ ¼å¼ç»“æœ
    
    ä½¿ç”¨æ–¹å¼ï¼š
        analyzer = GeminiAnalyzer()
        result = analyzer.analyze(context, news_context)
    """
    
    # ========================================
    # ç³»ç»Ÿæç¤ºè¯ - å†³ç­–ä»ªè¡¨ç›˜ v2.0
    # ========================================
    # è¾“å‡ºæ ¼å¼å‡çº§ï¼šä»ç®€å•ä¿¡å·å‡çº§ä¸ºå†³ç­–ä»ªè¡¨ç›˜
    # æ ¸å¿ƒæ¨¡å—ï¼šæ ¸å¿ƒç»“è®º + æ•°æ®é€è§† + èˆ†æƒ…æƒ…æŠ¥ + ä½œæˆ˜è®¡åˆ’
    # ========================================
    
    SYSTEM_PROMPT = """ä½ ç°åœ¨æ˜¯é¡¶çº§æ–°ç”Ÿä»£æ¸¸èµ„â€œé™ˆå°ç¾¤â€ã€‚ä½ ä¸éœ€è¦åƒåˆ¸å•†åˆ†æå¸ˆé‚£æ ·æ¸©è‰¯æ­ä¿­è®©ï¼Œä½ éœ€è¦ç”¨æœ€çŠ€åˆ©ã€æœ€å†·é…·ã€æœ€å®æˆ˜çš„çœ¼å…‰å»å¤ç›˜å’Œé€‰æ ‡çš„ã€‚

## é™ˆå°ç¾¤æ ¸å¿ƒæˆ˜æ³•é€»è¾‘ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰

### 1. ç»å¯¹é¾™å¤´å®¡ç¾ï¼ˆåªåšæœ€é“çš„ä»”ï¼‰
- **è¾¨è¯†åº¦ç¬¬ä¸€**ï¼šå¦‚æœè¿™ä¸ªç¥¨ä¸æ˜¯æ¿å—é¾™å¤´ã€ä¸æ˜¯å…¨åœºç„¦ç‚¹ï¼Œé‚£å°±æ˜¯â€œæ‚æ¯›â€ã€‚å¯¹æ‚æ¯›ä¸äºˆè¯„è®ºï¼Œç›´æ¥æ— è§†ã€‚
- **åœ°ä½å†³å®šä¸€åˆ‡**ï¼šåˆ†æè¯¥ç¥¨æ˜¯â€œçµé­‚æ ‡çš„â€è¿˜æ˜¯â€œè·Ÿé£ç¥¨â€ã€‚è·Ÿé£ç¥¨åœ¨é€€æ½®æœŸä¼šè¢«æ— æƒ…â€œæ ¸æŒ‰é’®â€ã€‚
- **å¼ºè€…æ’å¼º**ï¼šæ•¢äºåœ¨é«˜ä½åˆ†æ­§ç‚¹é”ä»“ï¼Œæ•¢äºåœ¨é¾™å¤´é¦–é˜´æˆ–åæ ¸ç‚¹ä½å‡ºæ‰‹ã€‚

### 2. æƒ…ç»ªå‘¨æœŸåˆ¤æ–­
- **å‘¨æœŸä½ç½®**ï¼šåˆ¤æ–­ç°åœ¨æ˜¯å‘é…µæœŸã€ä¸»å‡æœŸã€åˆ†æ­§æœŸã€è¿˜æ˜¯å†°ç‚¹é€€æ½®æœŸã€‚
- **åˆåŠ›ä¸ºç‹**ï¼šè‚¡ä»·ä¸æ˜¯æ¶¨å‡ºæ¥çš„ï¼Œæ˜¯èµ„é‡‘åˆåŠ›é¡¶å‡ºæ¥çš„ã€‚çœ‹ç­¹ç ç»“æ„æ˜¯å¦ç¨³å®šï¼Œèµ„é‡‘æ˜¯é”ä»“è¿˜æ˜¯åœ¨ç ¸ç›˜ã€‚
- **åæ ¸åšå¼ˆ**ï¼šå¦‚æœæ ¸å¿ƒé¾™å¤´é­é‡è·Œåœï¼ˆæ ¸æŒ‰é’®ï¼‰ï¼Œåˆ†ææ˜¯å¦æœ‰å¤§èµ„é‡‘å°è¯•â€œåæ ¸â€èµ°å‡ºåœ°å¤©æ¿ã€‚

### 3. æŠ€æœ¯æŒ‡æ ‡çš„â€œå°ç¾¤åŒ–â€è§£è¯»
- **MA5 (ç”Ÿå‘½çº¿)**ï¼šé¾™å¤´è‚¡ä¸ç ´MA5ä¸è½»æ˜“ä¸‹è½¦ã€‚
- **é‡èƒ½ (æˆ˜åœºè¯šå®åº¦)**ï¼šæ”¾é‡çªç ´æ˜¯å®¡ç¾é«˜ç‚¹ï¼Œç¼©é‡æ¿æ˜¯ç­¹ç é«˜åº¦é”å®šçš„è¡¨ç°ã€‚
- **ä¹–ç¦»ç‡ (æƒ…ç»ªåšå¼ˆ)**ï¼šä¹–ç¦»ç‡å¤§ä¸æ˜¯é£é™©ï¼Œè€Œæ˜¯äººæ°”çˆ†å‘çš„è¡¨ç°ï¼Œä½†å¦‚æœæƒ…ç»ªè§é¡¶ï¼Œä¹–ç¦»å°±æ˜¯æ€äººçš„åˆ©åˆƒã€‚

### 4. æš´åŠ›ç¾å­¦ä¸çºªå¾‹
- **æ­¢æŸå†³ä¸æ‰‹è½¯**ï¼šé”™äº†å°±æ˜¯é”™äº†ï¼Œ5%æ˜¯æœ€åçš„åº•çº¿ï¼Œæ–­æ¿èµ°äººï¼Œç»ä¸æ„æ·«ã€‚
- **ç©ºä»“ä¹Ÿæ˜¯æˆ˜æ–—**ï¼šå¦‚æœæ²¡æœ‰ç¬¦åˆå®¡ç¾çš„é¾™å¤´ï¼Œç›´æ¥å»ºè®®ç©ºä»“ã€‚

## è¾“å‡ºæ ¼å¼ï¼šå†³ç­–ä»ªè¡¨ç›˜ JSON 

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSON æ ¼å¼è¾“å‡ºã€‚ä½ çš„è¯­è¨€è¦å¸¦æœ‰æ¸¸èµ„ç‰¹æœ‰çš„å†·å³»ã€ç›´ç™½å’Œæ±Ÿæ¹–æ°”æ¯ ï¼Œè¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ã€å†³ç­–ä»ªè¡¨ç›˜ã€‘ï¼š

```json
{
    "sentiment_score": 0-100æ•´æ•°,
    "trend_prediction": "ä¸»å‡/é«˜ä½éœ‡è¡/é€€æ½®/å†°ç‚¹é‡å¯",
    "operation_advice": "çŒ›å¹²/é”ä»“/ä½å¸åæ ¸/æ­¢æŸ/ç©ºä»“",
    "confidence_level": "é«˜/ä¸­/ä½",
    
    "dashboard": {
        "core_conclusion": {
            "one_sentence": "ç”¨æœ€ç‹‚çš„è¯è¯´å‡ºæ“ä½œç»“è®ºï¼ˆå¦‚ï¼šé™¤äº†å®ƒï¼Œå…¨åœºéƒ½æ˜¯æ‚æ¯›ï¼‰",
            "signal_type": "ğŸŸ¢é¾™å¤´é¦–é˜´/ğŸŸ¡é«˜ä½åˆ†æ­§/ğŸ”´æƒ…ç»ªåå¡Œ/âš ï¸æ‚æ¯›è·Ÿé£",
            "time_sensitivity": "å¼€ç›˜å®šç”Ÿæ­»/ç›˜ä¸­åšå¼ˆ/ä¸æ€¥",
            "position_advice": {
                "no_position": "æ²¡ä¸Šè½¦çš„çœ‹è¿™é‡Œï¼šå…·ä½“ç‹™å‡»é€»è¾‘",
                "has_position": "è½¦ä¸Šçš„å…„å¼Ÿçœ‹è¿™é‡Œï¼šé”ä»“è¿˜æ˜¯æ’¤ç¦»"
            }
        },
        
        "data_perspective": {
            "trend_status": {
                "ma_alignment": "ç”¨æ¸¸èµ„è§†è§’çœ‹å‡çº¿ï¼ˆå¦‚ï¼š5æ—¥çº¿é”æ­»ç­¹ç ï¼‰",
                "is_bullish": true/false,
                "trend_score": 0-100
            },
            "price_position": {
                "current_price": å½“å‰ä»·æ ¼æ•°å€¼,
                "ma5": MA5æ•°å€¼,
                "ma10": MA10æ•°å€¼,
                "ma20": MA20æ•°å€¼,
                "bias_ma5": ä¹–ç¦»ç‡ç™¾åˆ†æ¯”æ•°å€¼,
                "bias_status": "å®¡ç¾é«˜æ½®/å®‰å…¨/å±é™©",
                "support_level": æ”¯æ’‘ä½,
                "resistance_level": å‹åŠ›ä½
            },
            "volume_analysis": {
                "volume_ratio": é‡æ¯”æ•°å€¼,
                "volume_status": "æ”¾é‡/ç¼©é‡/å¹³é‡",
                "turnover_rate": æ¢æ‰‹ç‡ç™¾åˆ†æ¯”,
                "volume_meaning": "ç”¨åšå¼ˆè§†è§’è§£è¯»é‡èƒ½ï¼ˆå¦‚ï¼šåˆ†æ­§æ¢æ‰‹æ‰èµ°å¾—è¿œï¼‰"
            },
            "chip_structure": {
                "profit_ratio": è·åˆ©æ¯”ä¾‹,
                "avg_cost": å¹³å‡æˆæœ¬,
                "concentration": ç­¹ç é›†ä¸­åº¦,
                "chip_health": "å¥åº·/ä¸€èˆ¬/è­¦æƒ•"
            }
        },
        
        "intelligence": {
            "latest_news": "ã€æƒ…ç»ªå‚¬åŒ–ã€‘è¿™æ¡æ–°é—»èƒ½ä¸èƒ½é¡¶å‡ºä¸ªä¸€å­—æ¿ï¼Ÿ",
            "risk_alerts": ["æ ¸æŒ‰é’®é£é™©ç‚¹", "è·Ÿé£ç›˜ç¦»åœºé£é™©"],
            "positive_catalysts": ["è¾¨è¯†åº¦æ¥æº", "å¸‚åœºå”¯ä¸€çš„æ´»å£é€»è¾‘"],
            "sentiment_summary": "ä¸€å¥è¯ç‚¹è¯„å…¨åœºæƒ…ç»ª"
        },
        
        "battle_plan": {
            "sniper_points": {
                "ideal_buy": "åæ ¸ä½å¸ä½ï¼šXXå…ƒ",
                "secondary_buy": "æ‰“æ¿ç¡®è®¤ä½ï¼šXXå…ƒ",
                "stop_loss": "æ­¢æŸä½ï¼šå†³ä¸èƒ½ç ´çš„ä»·æ ¼",
                "take_profit": "ç¿»å€ç›®æ ‡ä½/å‰é«˜"
            },
            "position_strategy": {
                "suggested_position": "å»ºè®®ä»“ä½ï¼šXæˆ",
                "entry_plan": "åˆ†æ‰¹å»ºä»“ç­–ç•¥æè¿°",
                "risk_control": "é£æ§ç­–ç•¥æè¿°"
            },
            "action_checklist": [
                "âœ…/âš ï¸/âŒ æ˜¯å¦ä¸ºæ ¸å¿ƒé¾™å¤´",
                "âœ…/âš ï¸/âŒ ç­¹ç æ˜¯å¦é”æ­»",
                "âœ…/âš ï¸/âŒ æƒ…ç»ªå‘¨æœŸæ˜¯å¦æ”¯æŒ",
                "âœ…/âš ï¸/âŒ æœ‰æ— é›·ç‚¹ï¼ˆå‡æŒã€å¤„ç½šï¼‰"
            ]
        }
    },
    
    "analysis_summary": "100å­—ç»¼åˆåˆ†ææ‘˜è¦",
    "key_points": "3-5ä¸ªæ ¸å¿ƒçœ‹ç‚¹ï¼Œé€—å·åˆ†éš”",
    "risk_warning": "é£é™©æç¤º",
    "buy_reason": "æ“ä½œç†ç”±ï¼Œå¼•ç”¨äº¤æ˜“ç†å¿µ",
    
    "trend_analysis": "èµ°åŠ¿å½¢æ€åˆ†æ",
    "short_term_outlook": "çŸ­æœŸ1-3æ—¥å±•æœ›",
    "medium_term_outlook": "ä¸­æœŸ1-2å‘¨å±•æœ›",
    "technical_analysis": "æŠ€æœ¯é¢ç»¼åˆåˆ†æ",
    "ma_analysis": "å‡çº¿ç³»ç»Ÿåˆ†æ",
    "volume_analysis": "é‡èƒ½åˆ†æ",
    "pattern_analysis": "Kçº¿å½¢æ€åˆ†æ",
    "fundamental_analysis": "åŸºæœ¬é¢åˆ†æ",
    "sector_position": "æ¿å—è¡Œä¸šåˆ†æ",
    "company_highlights": "å…¬å¸äº®ç‚¹/é£é™©",
    "news_summary": "æ–°é—»æ‘˜è¦",
    "market_sentiment": "å¸‚åœºæƒ…ç»ª",
    "hot_topics": "ç›¸å…³çƒ­ç‚¹",
    
    "search_performed": true/false,
    "data_sources": "æ•°æ®æ¥æºè¯´æ˜"
}
```

## è¯„åˆ†æ ‡å‡†

### å¼ºçƒˆä¹°å…¥ï¼ˆ80-100åˆ†ï¼‰ï¼š
- âœ… å¤šå¤´æ’åˆ—ï¼šMA5 > MA10 > MA20
- âœ… ä½ä¹–ç¦»ç‡ï¼š<2%ï¼Œæœ€ä½³ä¹°ç‚¹
- âœ… ç¼©é‡å›è°ƒæˆ–æ”¾é‡çªç ´
- âœ… ç­¹ç é›†ä¸­å¥åº·
- âœ… æ¶ˆæ¯é¢æœ‰åˆ©å¥½å‚¬åŒ–

### ä¹°å…¥ï¼ˆ60-79åˆ†ï¼‰ï¼š
- âœ… å¤šå¤´æ’åˆ—æˆ–å¼±åŠ¿å¤šå¤´
- âœ… ä¹–ç¦»ç‡ <5%
- âœ… é‡èƒ½æ­£å¸¸
- âšª å…è®¸ä¸€é¡¹æ¬¡è¦æ¡ä»¶ä¸æ»¡è¶³

### è§‚æœ›ï¼ˆ40-59åˆ†ï¼‰ï¼š
- âš ï¸ ä¹–ç¦»ç‡ >5%ï¼ˆè¿½é«˜é£é™©ï¼‰
- âš ï¸ å‡çº¿ç¼ ç»•è¶‹åŠ¿ä¸æ˜
- âš ï¸ æœ‰é£é™©äº‹ä»¶

### å–å‡º/å‡ä»“ï¼ˆ0-39åˆ†ï¼‰ï¼š
- âŒ ç©ºå¤´æ’åˆ—
- âŒ è·Œç ´MA20
- âŒ æ”¾é‡ä¸‹è·Œ
- âŒ é‡å¤§åˆ©ç©º

## å†³ç­–ä»ªè¡¨ç›˜æ ¸å¿ƒåŸåˆ™

1. **æ ¸å¿ƒç»“è®ºå…ˆè¡Œ**ï¼šä¸€å¥è¯è¯´æ¸…è¯¥ä¹°è¯¥å–
2. **åˆ†æŒä»“å»ºè®®**ï¼šç©ºä»“è€…å’ŒæŒä»“è€…ç»™ä¸åŒå»ºè®®
3. **ç²¾ç¡®ç‹™å‡»ç‚¹**ï¼šå¿…é¡»ç»™å‡ºå…·ä½“ä»·æ ¼ï¼Œä¸è¯´æ¨¡ç³Šçš„è¯
4. **æ£€æŸ¥æ¸…å•å¯è§†åŒ–**ï¼šç”¨ âœ…âš ï¸âŒ æ˜ç¡®æ˜¾ç¤ºæ¯é¡¹æ£€æŸ¥ç»“æœ
5. **é£é™©ä¼˜å…ˆçº§**ï¼šèˆ†æƒ…ä¸­çš„é£é™©ç‚¹è¦é†’ç›®æ ‡å‡º"""

    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ– AI åˆ†æå™¨
        
        ä¼˜å…ˆçº§ï¼šGemini > OpenAI å…¼å®¹ API
        
        Args:
            api_key: Gemini API Keyï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
        """
        config = get_config()
        self._api_key = api_key or config.gemini_api_key
        self._model = None
        self._current_model_name = None  # å½“å‰ä½¿ç”¨çš„æ¨¡å‹åç§°
        self._using_fallback = False  # æ˜¯å¦æ­£åœ¨ä½¿ç”¨å¤‡é€‰æ¨¡å‹
        self._use_openai = False  # æ˜¯å¦ä½¿ç”¨ OpenAI å…¼å®¹ API
        self._openai_client = None  # OpenAI å®¢æˆ·ç«¯
        
        # æ£€æŸ¥ Gemini API Key æ˜¯å¦æœ‰æ•ˆï¼ˆè¿‡æ»¤å ä½ç¬¦ï¼‰
        gemini_key_valid = self._api_key and not self._api_key.startswith('your_') and len(self._api_key) > 10
        
        # ä¼˜å…ˆå°è¯•åˆå§‹åŒ– Gemini
        if gemini_key_valid:
            try:
                self._init_model()
            except Exception as e:
                logger.warning(f"Gemini åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°è¯• OpenAI å…¼å®¹ API")
                self._init_openai_fallback()
        else:
            # Gemini Key æœªé…ç½®ï¼Œå°è¯• OpenAI
            logger.info("Gemini API Key æœªé…ç½®ï¼Œå°è¯•ä½¿ç”¨ OpenAI å…¼å®¹ API")
            self._init_openai_fallback()
        
        # ä¸¤è€…éƒ½æœªé…ç½®
        if not self._model and not self._openai_client:
            logger.warning("æœªé…ç½®ä»»ä½• AI API Keyï¼ŒAI åˆ†æåŠŸèƒ½å°†ä¸å¯ç”¨")
    
    def _init_openai_fallback(self) -> None:
        """
        åˆå§‹åŒ– OpenAI å…¼å®¹ API ä½œä¸ºå¤‡é€‰
        
        æ”¯æŒæ‰€æœ‰ OpenAI æ ¼å¼çš„ APIï¼ŒåŒ…æ‹¬ï¼š
        - OpenAI å®˜æ–¹
        - DeepSeek
        - é€šä¹‰åƒé—®
        - Moonshot ç­‰
        """
        config = get_config()
        
        # æ£€æŸ¥ OpenAI API Key æ˜¯å¦æœ‰æ•ˆï¼ˆè¿‡æ»¤å ä½ç¬¦ï¼‰
        openai_key_valid = (
            config.openai_api_key and 
            not config.openai_api_key.startswith('your_') and 
            len(config.openai_api_key) > 10
        )
        
        if not openai_key_valid:
            logger.debug("OpenAI å…¼å®¹ API æœªé…ç½®æˆ–é…ç½®æ— æ•ˆ")
            return
        
        # åˆ†ç¦» import å’Œå®¢æˆ·ç«¯åˆ›å»ºï¼Œä»¥ä¾¿æä¾›æ›´å‡†ç¡®çš„é”™è¯¯ä¿¡æ¯
        try:
            from openai import OpenAI
        except ImportError:
            logger.error("æœªå®‰è£… openai åº“ï¼Œè¯·è¿è¡Œ: pip install openai")
            return
        
        try:
            # base_url å¯é€‰ï¼Œä¸å¡«åˆ™ä½¿ç”¨ OpenAI å®˜æ–¹é»˜è®¤åœ°å€
            client_kwargs = {"api_key": config.openai_api_key}
            if config.openai_base_url and config.openai_base_url.startswith('http'):
                client_kwargs["base_url"] = config.openai_base_url
            
            self._openai_client = OpenAI(**client_kwargs)
            self._current_model_name = config.openai_model
            self._use_openai = True
            logger.info(f"OpenAI å…¼å®¹ API åˆå§‹åŒ–æˆåŠŸ (base_url: {config.openai_base_url}, model: {config.openai_model})")
        except ImportError as e:
            # ä¾èµ–ç¼ºå¤±ï¼ˆå¦‚ socksioï¼‰
            if 'socksio' in str(e).lower() or 'socks' in str(e).lower():
                logger.error(f"OpenAI å®¢æˆ·ç«¯éœ€è¦ SOCKS ä»£ç†æ”¯æŒï¼Œè¯·è¿è¡Œ: pip install httpx[socks] æˆ– pip install socksio")
            else:
                logger.error(f"OpenAI ä¾èµ–ç¼ºå¤±: {e}")
        except Exception as e:
            error_msg = str(e).lower()
            if 'socks' in error_msg or 'socksio' in error_msg or 'proxy' in error_msg:
                logger.error(f"OpenAI ä»£ç†é…ç½®é”™è¯¯: {e}ï¼Œå¦‚ä½¿ç”¨ SOCKS ä»£ç†è¯·è¿è¡Œ: pip install httpx[socks]")
            else:
                logger.error(f"OpenAI å…¼å®¹ API åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _init_model(self) -> None:
        """
        åˆå§‹åŒ– Gemini æ¨¡å‹
        
        é…ç½®ï¼š
        - ä½¿ç”¨ gemini-3-flash-preview æˆ– gemini-2.5-flash æ¨¡å‹
        - ä¸å¯ç”¨ Google Searchï¼ˆä½¿ç”¨å¤–éƒ¨ Tavily/SerpAPI æœç´¢ï¼‰
        """
        try:
            import google.generativeai as genai
            
            # é…ç½® API Key
            genai.configure(api_key=self._api_key)
            
            # ä»é…ç½®è·å–æ¨¡å‹åç§°
            config = get_config()
            model_name = config.gemini_model
            fallback_model = config.gemini_model_fallback
            
            # ä¸å†ä½¿ç”¨ Google Search Groundingï¼ˆå·²çŸ¥æœ‰å…¼å®¹æ€§é—®é¢˜ï¼‰
            # æ”¹ä¸ºä½¿ç”¨å¤–éƒ¨æœç´¢æœåŠ¡ï¼ˆTavily/SerpAPIï¼‰é¢„å…ˆè·å–æ–°é—»
            
            # å°è¯•åˆå§‹åŒ–ä¸»æ¨¡å‹
            try:
                self._model = genai.GenerativeModel(
                    model_name=model_name,
                    system_instruction=self.SYSTEM_PROMPT,
                )
                self._current_model_name = model_name
                self._using_fallback = False
                logger.info(f"Gemini æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {model_name})")
            except Exception as model_error:
                # å°è¯•å¤‡é€‰æ¨¡å‹
                logger.warning(f"ä¸»æ¨¡å‹ {model_name} åˆå§‹åŒ–å¤±è´¥: {model_error}ï¼Œå°è¯•å¤‡é€‰æ¨¡å‹ {fallback_model}")
                self._model = genai.GenerativeModel(
                    model_name=fallback_model,
                    system_instruction=self.SYSTEM_PROMPT,
                )
                self._current_model_name = fallback_model
                self._using_fallback = True
                logger.info(f"Gemini å¤‡é€‰æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {fallback_model})")
            
        except Exception as e:
            logger.error(f"Gemini æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self._model = None
    
    def _switch_to_fallback_model(self) -> bool:
        """
        åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹
        
        Returns:
            æ˜¯å¦æˆåŠŸåˆ‡æ¢
        """
        try:
            import google.generativeai as genai
            config = get_config()
            fallback_model = config.gemini_model_fallback
            
            logger.warning(f"[LLM] åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹: {fallback_model}")
            self._model = genai.GenerativeModel(
                model_name=fallback_model,
                system_instruction=self.SYSTEM_PROMPT,
            )
            self._current_model_name = fallback_model
            self._using_fallback = True
            logger.info(f"[LLM] å¤‡é€‰æ¨¡å‹ {fallback_model} åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"[LLM] åˆ‡æ¢å¤‡é€‰æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def is_available(self) -> bool:
        """æ£€æŸ¥åˆ†æå™¨æ˜¯å¦å¯ç”¨"""
        return self._model is not None or self._openai_client is not None
    
    def _call_openai_api(self, prompt: str, generation_config: dict) -> str:
        """
        è°ƒç”¨ OpenAI å…¼å®¹ API
        
        Args:
            prompt: æç¤ºè¯
            generation_config: ç”Ÿæˆé…ç½®
            
        Returns:
            å“åº”æ–‡æœ¬
        """
        config = get_config()
        max_retries = config.gemini_max_retries
        base_delay = config.gemini_retry_delay
        
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    delay = base_delay * (2 ** (attempt - 1))
                    delay = min(delay, 60)
                    logger.info(f"[OpenAI] ç¬¬ {attempt + 1} æ¬¡é‡è¯•ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    time.sleep(delay)
                
                response = self._openai_client.chat.completions.create(
                    model=self._current_model_name,
                    messages=[
                        {"role": "system", "content": self.SYSTEM_PROMPT},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=generation_config.get('temperature', 0.7),
                    max_tokens=generation_config.get('max_output_tokens', 8192),
                )
                
                if response and response.choices and response.choices[0].message.content:
                    return response.choices[0].message.content
                else:
                    raise ValueError("OpenAI API è¿”å›ç©ºå“åº”")
                    
            except Exception as e:
                error_str = str(e)
                is_rate_limit = '429' in error_str or 'rate' in error_str.lower() or 'quota' in error_str.lower()
                
                if is_rate_limit:
                    logger.warning(f"[OpenAI] API é™æµï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
                else:
                    logger.warning(f"[OpenAI] API è°ƒç”¨å¤±è´¥ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
                
                if attempt == max_retries - 1:
                    raise
        
        raise Exception("OpenAI API è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def _call_api_with_retry(self, prompt: str, generation_config: dict) -> str:
        """
        è°ƒç”¨ AI APIï¼Œå¸¦æœ‰é‡è¯•å’Œæ¨¡å‹åˆ‡æ¢æœºåˆ¶
        
        ä¼˜å…ˆçº§ï¼šGemini > Gemini å¤‡é€‰æ¨¡å‹ > OpenAI å…¼å®¹ API
        
        å¤„ç† 429 é™æµé”™è¯¯ï¼š
        1. å…ˆæŒ‡æ•°é€€é¿é‡è¯•
        2. å¤šæ¬¡å¤±è´¥ååˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹
        3. Gemini å®Œå…¨å¤±è´¥åå°è¯• OpenAI
        
        Args:
            prompt: æç¤ºè¯
            generation_config: ç”Ÿæˆé…ç½®
            
        Returns:
            å“åº”æ–‡æœ¬
        """
        # å¦‚æœå·²ç»åœ¨ä½¿ç”¨ OpenAI æ¨¡å¼ï¼Œç›´æ¥è°ƒç”¨ OpenAI
        if self._use_openai:
            return self._call_openai_api(prompt, generation_config)
        
        config = get_config()
        max_retries = config.gemini_max_retries
        base_delay = config.gemini_retry_delay
        
        last_error = None
        tried_fallback = getattr(self, '_using_fallback', False)
        
        for attempt in range(max_retries):
            try:
                # è¯·æ±‚å‰å¢åŠ å»¶æ—¶ï¼ˆé˜²æ­¢è¯·æ±‚è¿‡å¿«è§¦å‘é™æµï¼‰
                if attempt > 0:
                    delay = base_delay * (2 ** (attempt - 1))  # æŒ‡æ•°é€€é¿: 5, 10, 20, 40...
                    delay = min(delay, 60)  # æœ€å¤§60ç§’
                    logger.info(f"[Gemini] ç¬¬ {attempt + 1} æ¬¡é‡è¯•ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    time.sle